\documentclass[10pt, twocolumn]{article}
\usepackage{../hw}
\title{Homework 11}
\author{Tarang Srivastava}

\begin{document}
\makechaptertitle

\section{Exercises 7.B}

\begin{q}[3]
    Define the linear map $ T $ as follows for each $ z = (z_1, z_2, z_3) \in \C^3 $.
    $$ Tz = (2z_1, 3z_2, 2z_1) $$
    Note the switch up in the last spot. 
    We can check that $ T $ is indeed closed under addition and scalar multiplication, thus a linear map.
    Firstly, $ \lambda = 2 $ is an eigenvalue with the eigenvector $ w = (1, 0, 1) $.
    $$ T(1, 0, 1) = (2, 0, 2) = 2(1, 0, 1) $$
    Similarly, $ \lambda = 3 $ is an eigenvalue with the eigenvector $ w = (0, 1, 0) $.
    $$ T(0, 1, 0) = (0, 3, 0) = 3(0, 1, 0) $$
    Finally, $ (T^2 - 5T + 6I)z \neq 0 $ if $ z_3 \neq 6 z_1 $. 
    So given we have values that are nonzero after that linear map, $ T^2 - 5T + 6I \neq 0 $.
\end{q}

\begin{q}[4]
    Given that $ \F = \C $ by the complex spectral theorem $ T $ is normal if and only if $ T $ has a diagonal matrix with respect to some orthonormal basis.
    Since $ T $ is diagonalizable if and only if $ V $ is equal to the sum of the eigenspaces of distinct eigenvalues, we have shown the last case.
    Also by the complex spectral theorem $ T $ is normal if and only if $ V $ has an orthonormal basis consisting of eigenvectors of $ T $.
    That completes the proof. 
    (Ask Alex if there's some part that guarantees that we have distinct eigenvalues, but it is not that difficult to show that if all the basis eigenvectors are orthogonal they must be associated with distinct eigenvalues.)
\end{q}

\begin{q}[6]
    $ \implies $ direction follows easily from 7.13, if $ T $ is self-adjoint then all the eigenvalues are real. \\
    $ \impliedby $ Given $ T $ is normal then $ T^* $ and $ T $ have the same eigenvectors 
    and for the corresponding eigenvalue $ \lambda $ for $ T $, $ T ^* $ has the associated eigenvalue $ \overline{\lambda} $ for the same eigenvector.
    If all the eigenvalues are real $ \lambda = \overline{\lambda} $, so $ T $ and $ T^* $ have the same eigenvalues and eigenvectors.
    By the complex spectral theorem $ V $ has an orthogonal basis consisting of eigenvectors of $ T $.
    Denote these basis eigenvectors as $ e_1, ..., e_n $.
    Let $ v \in V $, then for some $ a_1, ..., a_n \in \C $
    \begin{align*}
    Tv &= a_1T(e_1) + ... + a_n T(e_n) \\
    &= a_1 \lambda_1 e_1 + ... + a_n \lambda_n e_n \\
    &= a_1T^*(e_1) + ... + a_n T^*(e_n) \\
    Tv &= T^*v
    \end{align*}
    For all $ v \in V $ so $ T = T^* $, therefore $ T $ is self adjoint.
\end{q}

\begin{q}[8]
    Let $ T $ be the operator associated with the matrix and some basis $ B $ for the complex vector space 
    $$ \mathcal{M}(T, B) =\left(\begin{array}{ccc}0 & \dots & 1 \\ & \ddots & \vdots \\ 0 & & 0\end{array}\right) $$
    Then, clearly $ T^2 = 0 $ so $ T \neq T^2 $ and $ T^8 = 0 = T^9 $.
    (I'm not sure what the point of this question was, but I definitely missed it.)
\end{q}

\begin{q}[10]
    Let $ V = \R^2 $ and $ T $ be the operator represented by this matrix for the standard basis of $ \R^2 $. 
    $$ \left(\begin{array}{cc}
        -1 & -2 \\
        1 & 1 
    \end{array} \right) $$
    For $ b = 0 $ and $ c = 1 $
    $$ \left(\begin{array}{cc}
        -1 & -2 \\
        1 & 1 
    \end{array} \right) 
    \left(\begin{array}{cc}
        -1 & -2 \\
        1 & 1 
    \end{array} \right)
    + (1) 
    \left(\begin{array}{cc}
        1 & 0 \\
        0 & 1 
    \end{array} \right)
    =
    0
    $$
    Since we can compute that $ T^2 = -I $. The zero operator is non invertible so we are done.
\end{q}

\begin{q}[11]
    By the real or complex spectral theorem given that $ T $ is self-adjoint it is diagonalizable. 
    Suppose the digaonal matrix is  
    $$ T = 
        \left(\begin{array}{ccc}a_1 & \dots & 0 \\ & \ddots & \vdots \\ 0 & & a_n\end{array}\right)
    $$
    Then, we can take the cube root of each value in the diagonal, which is well defined for complex or real numbers.
    So we get 
    $$ S = 
        \left(\begin{array}{ccc} a_1^{1/3} & \dots & 0 \\ & \ddots & \vdots \\ 0 & & a_n^{1/3}\end{array}\right)
    $$
    Then, clearly it holds that $ S^3 = T $.
\end{q}

\begin{q}[12]
    By the spectral theorem there exists an orthonormal basis of $ V $ consisiting of eigenvectors of $ T $.
    So $ v $ is equal to 
    $$ v = a_1 e_1 + ... + a_n e_n $$ 
    Where, the $ a_1, ..., a_n $ are some scalars and the $ e_1, ..., e_n $ are the orthonormal basis eigenvectors.
    Then, 
    $$ Tv = a_1 \lambda_1 e_1 + ... + a_n \lambda_n e_n $$ 
    So we can restate the inequality as 
    \begin{align*}
    \norm{Tv - \lambda v}  &= \norm{a_1 \lambda_1 e_1 + ... + a_n \lambda_n e_n - \lambda v} \\
    &= \norm{ \abs{\lambda_1 - \lambda} a_1 e_1 + ... + \abs{\lambda_1 - \lambda} a_n e_n} \\
    \intertext{Then since the basis vectors are orthogonal we can express them as}
    &= \norm{\abs{\lambda_1 - \lambda} + ... + \abs{\lambda_1 - \lambda}}\norm{a_1 e_1 + ... + a_n e_n} \\
    \intertext{Following that $ \norm{v} = 1 $}
    &= \norm{\abs{\lambda_1 - \lambda} + ... + \abs{\lambda_1 - \lambda}} \\
    \end{align*}
    So we are given that 
    $$ \norm{\abs{\lambda_1 - \lambda} + ... + \abs{\lambda_1 - \lambda}} < \epsilon $$
    Assume for contradiction that $ \abs{\lambda - \lambda_i} \geq \epsilon $ for all $ i \in 1, ..., n $.
    Then, we can make the following substitutions
    $$ \norm{\epsilon + ... + \epsilon} = n \epsilon < \epsilon $$ 
    Which then implies that $ n < 1 $ which is a contradiction since it would imply that $ V $ has dimension 0, but it clearly doesn't since $ v \in V $ and $ \norm{v} = 1 $.
    Thus, we have a contradiction and it must be that there exists some eigenvalue $ \lambda' $ the statement holds.
\end{q}

\begin{q}[13]
    The first part of (c) if and only if (a) we proceed as in the provided proof. 
    Then to show that the last part that (a) implies (b) we note that if our operator is normal, 
    then we have to consider a basis eigenvector $ v $ such that
\end{q}

\begin{q}[14]
    $ \impliedby $ By the real spectral theorem if $ T $ is self-adjoint and the inner product makes $ U $ an inner product space, 
    then $ U $ has a basis consisting of eigenvectors of $ T $. \\
    $ \implies $ If $ T $ has a basis consisiting of eigenvectors, then it is diagonalizable by 5.41. 
    Now if we just provide an inner product on $ U $ such that the basis eigenvectors are orthonormal we can just apply the real spectral theorem and be done.\\
    Let $ e_1, .., e_n $ be the eigenvector basis. Then, for arbitrary $ v, w \in V $ 
    $$ v = a_1 e_1 + ... + a_n e_n $$
    and 
    $$ w = b_1 e_1 + ... + b_n e_n $$
    For some real number scalars.
    we define the inner product $ \ip{v, w} $ as follows 
    $$ \ip{v, w} = a_1 \cdot b_1 + ... + a_n \cdot b_n $$
    We will now confirm that all the properties of an inner product do indeed hold.
    \begin{enumerate}
        \item Positivity: Observe that $ \ip{v, v} = a_1^2 + ... + a_n^2 \geq 0 $.
        \item Definiteness: By the property of linearly independent vectors, 
        $ \ip{v, v} = a_1^2 + ... + a_n^2 = 0 $ only when $ a_1 = ... = a_n = 0 $ which is when $ v = 0 $.
        \item Additivity: pretty straightforward from the commutitivity and distributivity in $ \R $.
        \item Homogeniety: straightforward from the distributivity of real numbers.
        \item Conjugate symmetry: Since we are in a real vector space conjugates are equal to the number itself. 
        So, $ \ip{v, w} = a_1 b_1 + ... + a_n b_n = b_1 a_1 + ... + b_n a_n = \ip{w, b} $ form the commutitivity of real numbers.
    \end{enumerate}
    Having done ALL that we can confirm that the basis eigenvectors are indeed normal and orthogonal in this definition of the inner product.
    This follows simply from the fact that $ <e_i, e_i > = 1 * 1 = 1 $ and we have that  $ < e_i, e_j > = 1 * 0 + 0 * 1 = 0 $ for different basis vectors. 
    Therefore, we can apply the real spectral theorem and get that $ T $ must be self adjoint, since there is a diagonal matrix of orthonormal basis.
\end{q}

\section{Exercise 7.C}

\begin{q}[1]
    Counterexample.
    Consider the operator $ T $ associated with the matrix  
    $$ \left(\begin{array}{cc}
        1 & -i \\
        i & -1 
    \end{array} \right) 
    $$
    Then observe that the matrix is equal to its conjugate transpose. 
    Then the vectors $ b_1 = (1/\sqrt{2}, i/\sqrt{2}) $ and $ b_2 = (1/\sqrt{2}, -i/\sqrt{2}) $ 
    form an orthonormal basis and it holds that 
    $ \ip{Tb_1, b_1} = 2 $ and $ \ip{Tb_2, b_2} = 2 $.
    With all that in place, for $ v = (1, 2) $ we have that 
    $$ \ip{Tv, v} = -3 $$
\end{q}

\begin{q}[2]
    
\end{q}

\end{document}